# Copyright (c) 2025 Efstratios Goudelis
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

from __future__ import annotations

import logging
import multiprocessing
import queue
import threading
import time
from dataclasses import asdict
from typing import Any, Dict, Union

from vfos.state import VFOManager


class IQBroadcaster(threading.Thread):
    """
    Reads IQ samples from a single source queue (multiprocessing.Queue from SDR worker)
    and broadcasts copies to multiple subscriber queues (one per active demodulator).

    This allows multiple VFOs/demodulators to process the same IQ samples simultaneously
    without gaps, as each gets its own complete copy of the sample stream.

    The broadcaster runs as a daemon thread and will automatically stop when the
    main process exits.
    """

    def __init__(self, source_queue, sdr_id: str):
        """
        Initialize the IQ broadcaster.

        Args:
            source_queue: The multiprocessing.Queue to read IQ samples from (from SDR worker)
            sdr_id: Identifier for this SDR device (used for logging)
        """
        super().__init__(daemon=True, name=f"IQBroadcaster-{sdr_id}")
        self.source_queue = source_queue
        self.sdr_id = sdr_id
        self.subscribers: Dict[str, dict] = {}  # session_id -> {queue, delivered, dropped}
        self.running = True
        self.lock = threading.Lock()
        self.logger = logging.getLogger("iq-broadcaster")

        # VFO state manager for injecting VFO states into IQ messages
        self.vfo_manager = VFOManager()

        # Performance monitoring stats
        self.stats: Dict[str, Any] = {
            "messages_in": 0,
            "messages_broadcast": 0,
            "messages_dropped": 0,
            "queue_timeouts": 0,
            "last_activity": None,
            "errors": 0,
        }
        self.stats_lock = threading.Lock()

    def subscribe(
        self, session_id: str, maxsize: int = 50, for_process: bool = False
    ) -> Union[queue.Queue[Any], multiprocessing.Queue[Any]]:
        """
        Create a new subscriber queue for a session.

        Args:
            session_id: Session identifier (client session ID)
            maxsize: Maximum size of the subscriber queue (default: 50)
                    If the demodulator can't keep up and the queue fills,
                    new samples will be dropped for that subscriber.
            for_process: If True, creates multiprocessing.Queue for Process subscribers.
                        Use this when subscriber is a multiprocessing.Process rather than
                        a threading.Thread. Default: False (threading queue)

        Returns:
            Queue that will receive copies of IQ samples (threading or multiprocessing)
        """
        with self.lock:
            if session_id not in self.subscribers:
                # Create appropriate queue type based on subscriber needs
                subscriber_queue: Union[queue.Queue[Any], multiprocessing.Queue[Any]]
                if for_process:
                    subscriber_queue = multiprocessing.Queue(maxsize=maxsize)
                    queue_type = "multiprocessing"
                else:
                    subscriber_queue = queue.Queue(maxsize=maxsize)
                    queue_type = "threading"

                self.subscribers[session_id] = {
                    "queue": subscriber_queue,
                    "maxsize": maxsize,
                    "is_process_queue": for_process,
                    "delivered": 0,
                    "dropped": 0,
                }
                self.logger.info(f"Subscribed session {session_id} (queue: {queue_type})")
            result: Union[queue.Queue[Any], multiprocessing.Queue[Any]] = self.subscribers[
                session_id
            ]["queue"]
            return result

    def unsubscribe(self, session_id: str):
        """
        Remove a subscriber queue.

        Args:
            session_id: Session identifier to unsubscribe
        """
        with self.lock:
            if session_id in self.subscribers:
                del self.subscribers[session_id]
                self.logger.info(f"Unsubscribed session {session_id}")

    def get_subscriber_count(self) -> int:
        """
        Get the number of active subscribers.

        Returns:
            int: Number of active subscriber queues
        """
        with self.lock:
            return len(self.subscribers)

    def flush_all_queues(self):
        """
        Flush (empty) all subscriber queues.

        This is useful when sample rate changes, since all buffered data
        at the old sample rate becomes invalid.
        """
        with self.lock:
            for session_id, subscriber_info in self.subscribers.items():
                subscriber_queue = subscriber_info["queue"]
                flushed_count = 0
                while not subscriber_queue.empty():
                    try:
                        subscriber_queue.get_nowait()
                        flushed_count += 1
                    except queue.Empty:
                        break
                if flushed_count > 0:
                    self.logger.debug(
                        f"Flushed {flushed_count} items from queue for session {session_id}"
                    )

    def _extract_session_id(self, subscription_key: str) -> str:
        """
        Extract session_id from subscription key.

        Subscription keys have format:
        - "decoder:{session_id}:vfo{N}" for decoders
        - "recorder:{session_id}" for recorders
        - "demodulator:{session_id}:vfo{N}" for audio demodulators

        Args:
            subscription_key: Subscription key string

        Returns:
            Session ID or empty string if not found
        """
        # Pattern to extract session_id from various subscription key formats
        # Subscription keys are: "type:session_id:vfo" or "type:session_id"
        # For internal sessions: "decoder:internal:obs-123:vfo1" -> need "internal:obs-123"
        # For regular sessions: "decoder:regular-session-id:vfo1" -> need "regular-session-id"
        parts = subscription_key.split(":")
        if len(parts) >= 2:
            # Check if this is an internal session (has "internal:" prefix)
            if len(parts) >= 4 and parts[1] == "internal":
                # "decoder:internal:obs-123:vfo1" -> "internal:obs-123"
                return f"{parts[1]}:{parts[2]}"
            elif len(parts) == 3:
                # "decoder:session_id:vfo1" -> "session_id"
                return parts[1]
            elif len(parts) == 2:
                # "decoder:session_id" -> "session_id"
                return parts[1]
        return ""

    def _enrich_iq_message_with_vfo_states(
        self, iq_message: Dict[str, Any], session_id: str
    ) -> Dict[str, Any]:
        """
        Add VFO states to IQ message for the given session.

        Fetches all VFO states for the session from VFOManager and adds them
        to the IQ message. Each decoder can then extract its specific VFO state.

        Args:
            iq_message: Original IQ message from SDR worker
            session_id: Session ID to fetch VFO states for

        Returns:
            Enriched IQ message with vfo_states dict added
        """
        try:
            # Get all VFO states for this session (returns dict of {vfo_number: VFOState})
            vfo_states = self.vfo_manager.get_all_vfo_states(session_id)

            # Convert VFOState dataclasses to dicts for serialization
            vfo_states_dict = {}
            for vfo_number, vfo_state in vfo_states.items():
                vfo_states_dict[vfo_number] = asdict(vfo_state)

            # Add to IQ message
            iq_message["vfo_states"] = vfo_states_dict

        except Exception as e:
            # If we fail to get VFO states, log but don't crash the broadcaster
            # The decoder will handle missing vfo_states gracefully
            self.logger.debug(f"Failed to get VFO states for session {session_id}: {e}")
            iq_message["vfo_states"] = {}

        return iq_message

    def run(self):
        """
        Main broadcaster loop.

        Continuously reads IQ samples from the source queue and broadcasts
        copies to all subscriber queues. If a subscriber's queue is full,
        the sample is dropped for that subscriber only.
        """
        self.logger.info(f"IQ broadcaster started for SDR {self.sdr_id}")

        while self.running:
            try:

                # Get IQ samples from the SDR worker process
                # Use timeout to allow checking self.running periodically
                try:
                    iq_message = self.source_queue.get(timeout=0.1)

                    # Update stats
                    with self.stats_lock:
                        self.stats["messages_in"] += 1
                        self.stats["last_activity"] = time.time()

                except queue.Empty:
                    with self.stats_lock:
                        self.stats["queue_timeouts"] += 1
                    continue

                # Broadcast to all subscribers
                with self.lock:
                    dead_subscribers = []
                    for subscription_key, subscriber_info in self.subscribers.items():
                        subscriber_queue = subscriber_info["queue"]
                        is_process_queue = subscriber_info.get("is_process_queue", False)

                        # Extract session_id from subscription key and enrich message with VFO states
                        session_id = self._extract_session_id(subscription_key)
                        if session_id:
                            # Create enriched message with VFO states for this specific session
                            enriched_message = self._enrich_iq_message_with_vfo_states(
                                iq_message.copy(), session_id
                            )
                        else:
                            # Fallback if we can't extract session_id (shouldn't happen)
                            enriched_message = iq_message.copy()
                            enriched_message["vfo_states"] = {}

                        try:
                            # Handle both threading and multiprocessing queues
                            if is_process_queue:
                                # Multiprocessing queue - use block=False
                                subscriber_queue.put(enriched_message, block=False)
                            else:
                                # Threading queue - use put_nowait()
                                subscriber_queue.put_nowait(enriched_message)

                            subscriber_info["delivered"] += 1
                            with self.stats_lock:
                                self.stats["messages_broadcast"] += 1

                        except (queue.Full, Exception) as e:
                            # Handle full queue for both types
                            if isinstance(e, queue.Full) or (
                                is_process_queue and "full" in str(e).lower()
                            ):
                                # Subscriber can't keep up - drop this sample
                                subscriber_info["dropped"] += 1
                                with self.stats_lock:
                                    self.stats["messages_dropped"] += 1
                            else:
                                # Mark subscriber for removal if there's an error
                                self.logger.warning(
                                    f"Error broadcasting to {subscription_key}: {e}"
                                )
                                dead_subscribers.append(subscription_key)

                    # Clean up dead subscribers
                    for dead_key in dead_subscribers:
                        del self.subscribers[dead_key]
                        self.logger.info(f"Removed dead subscriber {dead_key}")

            except Exception as e:
                if self.running:
                    self.logger.error(f"Error in broadcaster loop: {e}")
                    self.logger.exception(e)
                    with self.stats_lock:
                        self.stats["errors"] += 1

        self.logger.info(f"IQ broadcaster stopped for SDR {self.sdr_id}")

    def stop(self):
        """
        Stop the broadcaster thread.
        """
        self.running = False
        self.logger.info(f"Stopping IQ broadcaster for SDR {self.sdr_id}")
